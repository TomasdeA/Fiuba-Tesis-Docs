
\section{Modalidad del Trabajo}

El presente trabajo se encuadra en la modalidad \textbf{Tesis de Ingeniería Electrónica}. Este documento describe 
el plan de tesis correspondiente a la primera etapa de un proyecto de investigación y desarrollo de mayor alcance, 
estructurado en dos etapas complementarias e independientes.

A lo largo del texto, el término \textit{proyecto} hará referencia al desarrollo integral del sistema completo, 
abarcando ambas etapas. En contraste, el término \textit{tesis} se utilizará para referirse específicamente al 
trabajo de investigación y desarrollo correspondiente a la primera etapa.

\section{Objetivo}

\subsection{Objetivo del proyecto}

El objetivo final del proyecto es desarrollar un sistema portátil de asistencia sensorial que permita a personas con ceguera o baja visión 
percibir su entorno mediante estímulos táctiles, con el fin de mejorar su seguridad, autonomía y capacidad de desplazamiento independiente.

La base científica del proyecto se apoya en el principio de neuroplasticidad sensorial, según el cual el cerebro es capaz de reorganizarse 
para explotar de manera más eficiente los sentidos restantes cuando la visión está reducida o ausente. A partir de este principio, el 
proyecto busca diseñar una interfaz que traduzca información espacial visual en señales hápticas útiles, interpretables y funcionales 
para la navegación asistida.

El proyecto se estructura en dos etapas, que se abordarán en tesis separadas:
\begin{itemize}
    \item \textbf{Captación del entorno y mapeo local (esta tesis).}
    \item \textbf{Traducción del mapa a una interfaz háptica.}
\end{itemize}

\subsection{Etapas del proyecto}

\subsubsection{Captación del entorno y mapeo local}

Esta etapa se centra en la adquisición y procesamiento de información tridimensional del entorno en tiempo real, 
con el objetivo de construir una representación espacial simplificada del espacio inmediato frente al usuario.

El propósito de esta representación es condensar la información visual relevante en un formato 
estructurado y de baja dimensionalidad, adecuado para su posterior traducción a una interfaz háptica.

Durante esta etapa se analizarán distintas estrategias de reducción, agregación y estructuración de la 
información de profundidad, con el fin de preservar los elementos espaciales más relevantes para la 
detección y evación de obstáculos, manteniendo al mismo tiempo baja latencia y estabilidad temporal.

En este contexto, el problema de ingeniería abordado en el marco de la tesis consiste en diseñar un 
sistema embebido capaz de adquirir información tridimensional del entorno, procesarla en tiempo real 
y generar una representación compacta, estable y de baja latencia, adecuada para ser utilizada como 
entrada de una interfaz háptica de asistencia a la movilidad.

\subsubsection{Traducción del entorno a un mapa táctil}

Consiste en representar la información espacial mediante estímulos hápticos. 
Estos pueden estar ubicados en distintas zonas del cuerpo y permitirán detectar proximidad u obstáculos a través de variaciones en intensidad, 
frecuencia o localización de la vibración.

Una vez desarrollados los módulos de percepción y salida háptica, se realizará la integración en un dispositivo portátil y autónomo que funcione 
en tiempo real.

\subsection{Objetivo de tesis}

Esta tesis se centra en la primera etapa: la captación del entorno y generación de un mapeo local compacto y estable en tiempo real.

\subsubsection{Objetivo técnico}

El objetivo técnico principal es desarrollar e implementar un módulo de percepción en ROS2 que, utilizando la cámara Intel 
RealSense D435i, genere en tiempo real una representación compacta del entorno a partir de información de profundidad, 
optimizada para su uso como entrada de una futura interfaz háptica de asistencia a la movilidad.

El módulo deberá procesar imágenes RGB-D en tiempo real mediante técnicas de filtrado espacial y temporal, aplicar estrategias 
de agregación y reducción de dimensionalidad, y producir como salida una matriz estructurada de baja resolución (por ejemplo, 
\(10 \times 5\)) que represente una proyección compacta de la información de profundidad correspondiente al instante actual, 
preservando la información espacial relevante para la detección de obstáculos.

Asimismo, el sistema publicará los resultados en tópicos ROS2 estandarizados y proporcionará una interfaz serial para la 
transmisión eficiente de la matriz compacta hacia un microcontrolador encargado del control de los actuadores hápticos, 
cuya implementación corresponde a la segunda etapa del proyecto y no forma parte de esta tesis.

Adicionalmente, se implementará una capa de mapeo local de corto alcance, conceptualmente separada de la representación 
instantánea de profundidad, destinada a conservar información reciente de obstáculos y reutilizarla como mecanismo 
de protección frente a oclusiones temporales y cambios de orientación del sensor.

Para este propósito se incorporará información proveniente de una unidad de medición inercial (IMU), que permitirá estimar la 
orientación del sensor y compensar los cambios de pose durante la construcción y actualización del mapa local.

Los parámetros numéricos, umbrales y criterios de decisión serán determinados y refinados mediante una fase inicial de calibración 
y pruebas experimentales.

\subsubsection{Métricas y criterios de evaluación}

El desempeño del sistema será evaluado mediante métricas cuantitativas orientadas a caracterizar precisión, estabilidad 
y desempeño temporal, siguiendo criterios habituales en evaluación de sistemas de percepción visual y mapeo local
~\cite{sturm12iros}.

En particular, se considerarán: 
(i) error de profundidad en escenarios controlados mediante referencias geométricas simples 
(p.\,ej., ajuste de plano y RMS error)~\cite{IntelRealSenseDepthTuning}, 
(ii) latencia end-to-end (captura → procesamiento → transmisión), 
(iii) desempeño en detección de obstáculos en escenarios controlados (precisión y recall bajo una definición operativa de obstáculo), 
(iv) estabilidad temporal del mapa local (variación temporal por celda), y 
(v) consumo de recursos computacionales (CPU y memoria) de la plataforma.

Estas métricas permitirán determinar la viabilidad del enfoque propuesto como módulo perceptual de un sistema de asistencia sensorial en tiempo real.

\section{Contexto y motivación}

\subsection{Problemática}

Las personas con ceguera o visión reducida enfrentan dificultades significativas al desplazarse por entornos desconocidos o dinámicos. 
Las herramientas de asistencia tradicionales, como el bastón blanco o los perros guía, presentan limitaciones en alcance, resolución espacial 
y capacidad de anticipación frente a obstáculos no detectables a corta distancia.

En los últimos años han surgido dispositivos electrónicos de asistencia que incorporan sensores activos, sin embargo, la mayoría de estas 
soluciones se basa en sensores puntuales de corto alcance, lo que restringe la cantidad y calidad de información espacial disponible para el usuario.

Considerando lo anterior, resulta relevante explorar el uso de sensores visuales de profundidad como medio para obtener representaciones espaciales 
más ricas del entorno inmediato, manteniendo al mismo tiempo portabilidad, baja latencia y simplicidad de interacción.

\subsection{Estado del arte del proyecto}

Se analizaron trabajos previos relacionados con dispositivos de asistencia sensorial para personas con discapacidad visual, 
destacando algunas propuestas representativas:

\begin{enumerate}
    \item \textbf{Chaleco vibrotáctil~\cite{Novich2015}:} utiliza arreglos de actuadores de vibración para transmitir patrones espaciales al usuario, 
    requiriendo movimientos corporales activos para explorar el entorno.
    \item \textbf{Bastón inteligente~\cite{Santos2023}:} detecta obstáculos mediante sensores de corto alcance, dependiendo del movimiento manual y 
    proporcionando información limitada al punto de contacto.
    \item \textbf{Pulsera ultrasónica~\cite{Petsiuk2019UltrasoundNavigation}:} emite vibraciones al detectar objetos cercanos, con baja resolución 
    espacial y fuerte 
    dependencia de la orientación del brazo.
\end{enumerate}

Estas propuestas evidencian la viabilidad de la retroalimentación háptica como canal sensorial alternativo, 
pero también ponen de manifiesto las limitaciones de las soluciones basadas en sensores puntuales y de baja resolución espacial.

\subsection{Enfoque general del proyecto}

El proyecto propone utilizar percepción visual basada en profundidad para construir representaciones espaciales densas del entorno inmediato, 
que posteriormente puedan ser traducidas a estímulos hápticos.

El sistema se montará en la cabeza del usuario, aprovechando la dirección natural de la mirada como eje principal de exploración. Esta configuración 
permite una percepción frontal continua del entorno sin necesidad de utilizar las manos ni modificar el patrón natural de locomoción.

A diferencia de las soluciones existentes, el proyecto se enfoca en obtener un mapa denso de profundidad mediante visión estéreo, con 
el objetivo de proporcionar una representación espacial más rica y estructurada, adecuada para una futura traducción háptica.

\section{Descripción de la Tesis}

\subsection{Áreas Profesionales de Relevancia}

El trabajo se encuadra principalmente dentro del área de Automatización y Control, debido a su enfoque en el desarrollo de 
sistemas de percepción y procesamiento en tiempo real, basados en tecnologías habitualmente utilizadas en robótica y navegación asistida.

Asimismo, el desarrollo propuesto involucra otras áreas propias de la Ingeniería Electrónica, tales como Sistemas Embebidos 
y Procesamiento de Señales e Imágenes, en tanto requiere el diseño e integración de hardware y software bajo restricciones 
de tiempo real, consumo y portabilidad.

\subsection{Arquitectura}

La tesis se desarrollará sobre el framework ROS2, aprovechando su modelo de comunicación basado en tópicos, servicios y 
acciones, y su ecosistema de herramientas para sensado, procesamiento en tiempo real y experimentación reproducible. 
Esto permite modularizar el sistema en nodos con responsabilidades bien definidas, facilitar el registro y análisis de 
datos (\textit{logging} y \textit{rosbags}) y acelerar el prototipado mediante paquetes existentes de la comunidad.

\subsection{Adquisición y medición de profundidad}

Se utilizará la cámara \textbf{Intel RealSense D435i}~\cite{RS-D457} como sensor principal de profundidad. 
Este dispositivo provee medición de profundidad por visión estéreo y una IMU integrada.

La captura y publicación de datos se realizará mediante \texttt{librealsense} y el paquete de soporte en ROS2 
provisto por Intel, que permite publicar en tópicos estandarizados las imágenes y la información asociada 
(calibración, \textit{frames} y \textit{timestamps}).

\subsubsection{Sistemas embebidos}

La plataforma de referencia propuesta es una \textbf{Raspberry Pi} (modelo a determinar), por su bajo consumo, 
soporte Linux y compatibilidad con ROS2. No obstante, la elección final dependerá de las mediciones de rendimiento 
(CPU, memoria y latencia) durante la fase de prototipado: si el procesamiento en la Raspberry Pi no satisface los 
requisitos temporales, se considerará el uso de una plataforma más potente (p. ej. NVIDIA Jetson Nano).

La arquitectura prevista separa el módulo de percepción y el microcontrolador que gestiona los actuadores hápticos. 
El protocolo serial y el formato de datos se definirán tras las pruebas de rendimiento y ancho de banda.

\section{Mejoras y Aportes al Proyecto}

El aporte principal de esta tesis es la validación y adaptación de métodos de evación de obstaculos y mapeo 
orientados a la robótica pero en contextos de asistencia a personas ciegas. Sienta las bases necesarias para 
integrar la percepción visual con módulos hápticos en futuras fases del proyecto.

\section{Estado del arte de la tesis}

En el ámbito de la robótica móvil y la navegación asistida, la percepción basada en profundidad mediante sensores RGB-D 
se ha consolidado como una herramienta fundamental para la construcción de representaciones espaciales locales del entorno.

Diversos trabajos han demostrado que, para aplicaciones de navegación reactiva y evitación de obstáculos en tiempo real, 
son suficientes y preferibles representaciones locales del entorno centradas en el robot (que responden rápidamente a 
cambios cercanos) frente a mapas globales consistentes, que requieren mayor procesamiento y pueden no ser necesarios 
para tareas inmediatas de reacción \cite{brock1999high}.

Asimismo, la disponibilidad de sensores estéreo compactos con IMU integrada ha permitido mejorar la estabilidad de las 
representaciones locales frente a movimientos rápidos y vibraciones, favoreciendo su uso en sistemas embarcados orientados 
a interacción directa con el entorno.

En este contexto, la presente tesis se inscribe en la línea de generación de representaciones espaciales locales de baja 
dimensionalidad a partir de información de profundidad, orientadas a aplicaciones de navegación asistida en tiempo real 
sobre plataformas embebidas.

\section{Plan de Trabajo y Entregables}

El plan de trabajo se organiza en las siguientes etapas, con una estimación aproximada de dedicación horaria para cada una:
\begin{itemize}
    \item Relevamiento bibliográfico y definición de métricas (70--80 horas).
    \item Implementación del pipeline de percepción (130--150 horas).
    \item Desarrollo del mapeo local y memoria temporal (110--130 horas).
    \item Integración de información inercial y compensación de orientación (45--55 horas).
    \item Evaluación experimental y análisis de resultados (90--110 horas).
    \item Redacción final de la tesis (100--120 horas).
\end{itemize}

La planificación propuesta es tentativo y podrá ajustarse en función de los resultados obtenidos durante el desarrollo del trabajo.

\section{Resultados esperados}

\subsection{Resultados esperados del proyecto global}

Se espera desarrollar un sistema portátil de asistencia sensorial capaz de proporcionar retroalimentación 
táctil en tiempo real a partir de percepción visual, orientado a mejorar la seguridad, autonomía y capacidad 
de desplazamiento independiente de personas con ceguera o baja visión.

El sistema final integrará módulos de percepción, mapeo local y salida háptica en una plataforma compacta y 
autónoma, validada experimentalmente en escenarios representativos de uso cotidiano.

\subsection{Resultados esperados de la tesis}

Como resultado de esta tesis se espera obtener:

\begin{itemize}
    \item Un módulo de percepción visual capaz de generar, en tiempo real, una representación compacta y 
    de baja dimensionalidad del entorno inmediato a partir de información de profundidad obtenida mediante sensores RGB-D.
    
    \item Un mecanismo de mapeo local de corto alcance que permita mantener una memoria espacial estable de 
    obstáculos recientemente observados, mejorando la consistencia temporal de la representación frente a 
    oclusiones y variaciones en la orientación del sensor.
    
    \item Un conjunto de estrategias de filtrado, agregación y compactación de información de profundidad, 
    diseñadas y validadas experimentalmente con el objetivo de lograr baja latencia y estabilidad temporal.
    
    \item Una interfaz de salida claramente definida y documentada para la transmisión eficiente de la representación 
    compacta instantánea y de la información asociada al mapa local hacia módulos externos.
    
    \item La integración de todos los desarrollos previos en una arquitectura modular basada en ROS2, orientada a su 
    reutilización y extensión en futuros trabajos.
\end{itemize}
